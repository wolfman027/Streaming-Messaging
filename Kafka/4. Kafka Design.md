> 它需要优雅地处理大量的数据积压，以便能够支持来自脱机系统的定期数据加载。Kafka Design
>
> Kafka 设计



# 1. 动机

我们设计Kafka是为了能够作为一个统一的平台来处理所有的实时数据馈送 [a large company might have](https://kafka.apache.org/documentation/#introduction)。要做到这一点，我们必须考虑相当广泛的用例集。

它**必须具有高吞吐量以支持大容量事件流**，例如实时日志聚合。

它需要**优雅地处理大量的数据积压**，以便能够支持来自脱机系统的定期数据加载。

这也意味着系统**必须处理低延迟交付**，以处理更传统的消息传递用例。

我们希望支持对这些提要进行分区、分布式和实时处理，以创建新的派生提要。这**激发了我们的分区和消费者模型**。

最后，在将流输入到其他数据系统中进行服务的情况下，我们知道系统必须能够**保证在出现机器故障时的容错性**。

支持这些用途使我们的设计具有许多独特的元素，更类似于数据库日志而不是传统的消息传递系统。

我们将在下面的部分中概述该设计的一些元素。



# 2. 持久性

> [ACM Queue article](https://queue.acm.org/detail.cfm?id=1563874) 需要回看

## 不要害怕文件系统！

Kafka 很大程度上依赖于文件系统来存储和缓存消息。人们普遍认为“磁盘很慢”，这使人们怀疑持久结构能否提供有竞争力的性能。实际上，根据使用方式的不同，磁盘的速度比人们预期的要慢得多，也要快得多；一个设计合理的磁盘结构通常可以和网络一样快。

关于磁盘性能的一个关键事实是，在过去十年中，硬盘驱动器的吞吐量与磁盘查找的延迟一直在偏离。因此，在一个由六个 7200 转 SATA 硬盘组成的 RAID-5 阵列的 [JBOD](https://en.wikipedia.org/wiki/Non-RAID_drive_architectures)（Just a Bunch Of Disks，即一堆独立磁盘）配置中，线性写入的性能约为600MB/秒，而随机写入的性能仅为约100k/秒——两者之间的差异超过了6000倍。这些线性读写是所有使用模式中最可预测的，并且由操作系统进行了大量优化。现代操作系统提供了预读和后写技术，这些技术以大块的倍数预取数据，并将较小的逻辑写分组为较大的物理写。关于这个问题的进一步讨论可以在 **[ACM Queue article](https://queue.acm.org/detail.cfm?id=1563874)** 中找到；他们实际上发现在某些情况下，顺序磁盘访问可能比随机内存访问更快！如下所示：

![jacobs3](img/jacobs3.jpg)

为了弥补这种性能差异，现代操作系统越来越积极地使用主存进行磁盘缓存。一个现代的操作系统会很高兴地将所有空闲内存转移到磁盘缓存中，而在内存回收时几乎没有性能损失。所有磁盘读写都将通过这个统一缓存。在不使用直接 I/O 的情况下，这个特性不容易关闭，所以即使一个进程维护了数据的进程内缓存，这个数据也可能会在操作系统页面缓存中复制，从而有效地将所有内容存储两次。

此外，我们是在 JVM 之上构建的，任何花时间研究 Java 内存使用的人都知道两件事：

1. 对象的内存开销非常高，通常是存储数据大小的两倍（甚至更糟）。
2. 随着堆内数据的增加，Java 垃圾收集变得越来越繁琐和缓慢。

由于这些因素，使用文件系统并依赖于 pagecache 要优于维护内存缓存或其他结构 —— 通过自动访问所有空闲内存，我们至少可以将可用缓存增加一倍，并且通过存储紧凑的字节结构而不是单个对象，可能会再次增加一倍。这样做将在32GB的机器上产生28-30GB的缓存，而不会产生GC惩罚。此外，即使服务重新启动，这个缓存也将保持温暖，而进程内缓存需要在内存中重建（对于10GB的缓存可能需要10分钟），否则它将需要从一个完全冷的缓存开始（这可能意味着糟糕的初始性能）。这也极大地简化了代码，因为维护缓存和文件系统之间一致性的所有逻辑现在都在操作系统中，这往往比一次性的进程内尝试更有效、更正确。如果您的磁盘使用情况倾向于线性读取，那么预读就是在每次读取磁盘时用有用的数据有效地预先填充这个缓存。

这暗示了一种非常简单的设计：与其在内存中维护尽可能多的内存，并在空间用完时恐慌地将其全部刷新到文件系统中，不如将其颠倒过来。所有数据都立即写入文件系统上的持久日志，而不必刷新到磁盘。实际上，这只是意味着它被转移到内核的页面缓存中。

这种以页面缓存为中心的设计风格在一篇关于Varnish设计的 [article](https://varnish-cache.org/wiki/ArchitectNotes) 中有描述（同时也有一些傲慢）。



## 常数时间满足

消息传递系统中使用的持久数据结构通常是每个消费者的队列，具有关联的 BTree 或其他通用随机访问数据结构，用于维护有关消息的元数据。BTrees 是可用的最通用的数据结构，使得在消息传递系统中支持各种各样的事务性和非事务性语义成为可能。不过，它们的成本也相当高：Btree 的操作是O(log N)。通常情况下，O(log N) 被认为本质上等同于常数时间，但对于磁盘操作来说并非如此。磁盘查找的速度为每次10毫秒，并且每个磁盘一次只能执行一次查找，因此并行性是有限的。因此，即使少量的磁盘搜索也会导致非常高的开销。由于存储系统混合了非常快的缓存操作和非常慢的物理磁盘操作，因此观察到的树结构的性能通常是超线性的，因为数据增加了固定的缓存 —— 也就是说，数据量翻倍会导致速度比翻倍还要慢。

直观地说，持久队列可以建立在简单的读取和追加文件的基础上，这是日志解决方案中常见的情况。这种结构的优点是所有操作都是0(1)，读操作不会阻塞写操作，也不会相互阻塞。这具有明显的性能优势，因为性能与数据大小完全解耦 —— 一台服务器现在可以充分利用许多便宜、低转速的1+TB SATA驱动器。虽然它们的寻道性能很差，但这些驱动器具有可接受的大读写性能，并且价格为1/3，容量为 3 倍。

在没有任何性能损失的情况下访问几乎无限的磁盘空间意味着我们可以提供消息传递系统中通常没有的一些特性。例如，在 Kafka 中，我们可以保留消息相对较长的一段时间（比如一周），而不是试图在消息被消耗后立即删除消息。这为消费者带来了很大的灵活性，我们将对此进行描述。



# 3. 效率

我们在提高效率方面下了很大的功夫。我们的主要用例之一是处理网络活动数据，这是非常大的量：每个页面视图可能产生几十个写。此外，我们假设发布的每条消息至少被一个（通常是多个）消费者读取，因此我们努力使消费尽可能便宜。

我们还从构建和运行许多类似系统的经验中发现，效率是有效的多租户操作的关键。如果下游基础设施服务很容易因为应用程序使用的小变化而成为瓶颈，那么这种小的变化通常会产生问题。通过非常快的速度，我们帮助确保应用程序将在基础设施之前在负载下翻转。当试图在集中式集群上运行支持数十或数百个应用程序的集中式服务时，这一点尤其重要，因为使用模式几乎每天都会发生变化。

我们在前一节中讨论了磁盘效率。一旦消除了不良的磁盘访问模式，这种类型的系统就会出现**两个常见的低效率原因**：

- 太多的小I/O操作
- 过多的字节复制。

小的 I/O 问题既发生在客户机和服务器之间，也发生在服务器自己的持久操作中。

为了避免这种情况，我们的协议是围绕“消息集”抽象构建的，该抽象自然地将消息分组在一起。这允许网络请求将消息分组在一起，并分摊网络往返的开销，而不是一次发送一条消息。反过来，服务器一次将消息块附加到其日志中，而消费者一次获取大的线性块。

这个简单的优化产生了数量级的速度提升。批处理导致更大的网络数据包，更大的顺序磁盘操作，连续的内存块等等，所有这些都允许Kafka 将随机消息写入的突发流转换为流向消费者的线性写入。

另一个低效率是字节复制。在低消息速率下，这不是问题，但在负载下影响很大。为了避免这种情况，我们采用了由生产者、代理和消费者共享的标准化二进制消息格式（因此数据块可以在它们之间传输而无需修改）。

代理维护的消息日志本身只是一个文件目录，每个目录由一系列消息集填充，这些消息集已以生产者和消费者使用的相同格式写入磁盘。维护这种通用格式可以优化最重要的操作：持久日志块的网络传输。现代 unix 操作系统为将数据从 pagecache 传输到套接字提供了高度优化的代码路径；在Linux中，这是通过 [sendfile system call](https://man7.org/linux/man-pages/man2/sendfile.2.html) 完成的。

为了理解 sendfile 的影响，理解从文件到套接字传输数据的通用数据路径是很重要的：

1. 操作系统将数据从磁盘读入内核空间中的 pagecache
2. 应用程序将数据从内核空间读入用户空间缓冲区
3. 应用程序将数据写回内核空间到套接字缓冲区中
4. 操作系统将数据从套接字缓冲区复制到通过网络发送的NIC缓冲区

![](img/1730673759480.jpg)

这显然是低效的，有四个副本和两个系统调用。通过使用 sendfile，允许操作系统将数据从 pagecache 直接发送到网络，从而避免了这种重复复制。因此，在这个优化的路径中，只需要对 NIC 缓冲区进行最后的复制。

我们期望一个常见的用例是一个主题上的多个消费者。使用上面的零复制优化，数据只被复制到 pagecache 中一次，并在每次使用时重用，而不是存储在内存中，并在每次读取时将其复制到用户空间。这允许以接近网络连接限制的速率使用消息。

pagecache 和 sendfile 的结合意味着，在 Kafka 集群中，消费者大多被赶上，你将看不到磁盘上的任何读取活动，因为它们将完全从缓存中提供数据。

TLS/SSL 库在用户空间中运行（内核中的 `SSL_sendfile` 目前不受 Kafka 支持）。由于这一限制，当启用 SSL 时不会使用 `sendfile`。有关启用 SSL 配置的详细信息，请参阅 `security.protocol` 和 `security.inter.broker.protocol`。

有关 Java 中 **sendfile** 和**零拷贝**支持的更多背景信息，请参阅本文 [article](https://developer.ibm.com/articles/j-zerocopy/)。



## 端到端批量压缩

在某些情况下，瓶颈实际上不是CPU或磁盘，而是网络带宽。对于需要在广域网上的数据中心之间发送消息的数据管道来说尤其如此。当然，用户总是可以一次压缩一个消息，而不需要Kafka的任何支持，但这可能导致非常低的压缩比，因为许多冗余是由于相同类型的消息之间的重复（例如 JSON 中的字段名或 web 日志中的用户代理或常见字符串值）。**有效的压缩需要将多个消息压缩在一起，而不是单独压缩每个消息。**

Kafka通过高效的批处理格式支持这一点。可以将一批消息分组、压缩并以这种形式发送到服务器。broker 将对批处理进行解压缩以验证它。例如，它验证批处理中的记录数是否与批头所声明的记录数相同。然后将这批消息以压缩形式写入磁盘。该批将在日志中保持压缩，并以压缩形式传输给消费者。消费者解压缩它接收到的任何压缩数据。

Kafka 支持 GZIP、 Snappy、LZ4 和 ZStandard 压缩协议。更多关于压缩的细节可以在 [here](https://cwiki.apache.org/confluence/display/KAFKA/Compression) 找到。

















